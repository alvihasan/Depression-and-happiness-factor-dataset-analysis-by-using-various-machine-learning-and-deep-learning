{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "decision_lab_02.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCSz2KQ2AAB5"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
        "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSatyxMwAImg"
      },
      "source": [
        "col_names = ['timestamp', 'acade-year', 'label', 'scale', 'gender', 'age', 'where', 'status', 'finan', 'copeup', 'fam', 'pressure', 'result', 'livingplace', 'support', 'smedia', 'infer', 'meal', 'sick', 'hobby', 'sleep']\n",
        "# load dataset\n",
        "depression = pd.read_csv(\"depression_dataset.csv\",names=col_names)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "pM6TSuCgAXJJ",
        "outputId": "89f89934-120c-423f-b1c1-ce0a48f91382"
      },
      "source": [
        "depression.drop([0], axis=0, inplace=True)\n",
        "depression.drop(['timestamp'], axis=1, inplace=True)\n",
        "# depression.head()\n",
        "depression.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>acade-year</th>\n",
              "      <th>label</th>\n",
              "      <th>scale</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>where</th>\n",
              "      <th>status</th>\n",
              "      <th>finan</th>\n",
              "      <th>copeup</th>\n",
              "      <th>fam</th>\n",
              "      <th>pressure</th>\n",
              "      <th>result</th>\n",
              "      <th>livingplace</th>\n",
              "      <th>support</th>\n",
              "      <th>smedia</th>\n",
              "      <th>infer</th>\n",
              "      <th>meal</th>\n",
              "      <th>sick</th>\n",
              "      <th>hobby</th>\n",
              "      <th>sleep</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4th year</td>\n",
              "      <td>Normal</td>\n",
              "      <td>65</td>\n",
              "      <td>Male</td>\n",
              "      <td>22</td>\n",
              "      <td>Home</td>\n",
              "      <td>Single</td>\n",
              "      <td>Yes</td>\n",
              "      <td>3</td>\n",
              "      <td>Good</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Family</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4th year</td>\n",
              "      <td>Good</td>\n",
              "      <td>75</td>\n",
              "      <td>Male</td>\n",
              "      <td>22</td>\n",
              "      <td>Home</td>\n",
              "      <td>Single</td>\n",
              "      <td>Yes</td>\n",
              "      <td>3</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Family</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2nd year</td>\n",
              "      <td>Bad</td>\n",
              "      <td>25</td>\n",
              "      <td>Male</td>\n",
              "      <td>22</td>\n",
              "      <td>Home</td>\n",
              "      <td>Single</td>\n",
              "      <td>Yes</td>\n",
              "      <td>2</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No one</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3rd year</td>\n",
              "      <td>Bad</td>\n",
              "      <td>25</td>\n",
              "      <td>Male</td>\n",
              "      <td>22</td>\n",
              "      <td>Home</td>\n",
              "      <td>Single</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1</td>\n",
              "      <td>Good</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Family</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1st year</td>\n",
              "      <td>Normal</td>\n",
              "      <td>50</td>\n",
              "      <td>Male</td>\n",
              "      <td>22</td>\n",
              "      <td>Home</td>\n",
              "      <td>Single</td>\n",
              "      <td>Yes</td>\n",
              "      <td>3</td>\n",
              "      <td>Good</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No one</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  acade-year   label scale gender age where  ... smedia infer meal sick hobby sleep\n",
              "1   4th year  Normal    65   Male  22  Home  ...    Yes   Yes  Yes   No    No     8\n",
              "2   4th year    Good    75   Male  22  Home  ...     No    No  Yes  Yes    No     6\n",
              "3   2nd year     Bad    25   Male  22  Home  ...    Yes   Yes  Yes  Yes   Yes     6\n",
              "4   3rd year     Bad    25   Male  22  Home  ...    Yes   Yes  Yes  Yes   Yes     6\n",
              "5   1st year  Normal    50   Male  22  Home  ...    Yes   Yes  Yes  Yes   Yes     6\n",
              "\n",
              "[5 rows x 20 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "F5pcz8_7AcOa",
        "outputId": "7ff95adc-885b-4e7f-f1cb-06d9bf6afdf8"
      },
      "source": [
        "dataset_encoded=depression.iloc[:,0:20]\n",
        "\n",
        "le=LabelEncoder()\n",
        "\n",
        "for i in dataset_encoded:\n",
        "    dataset_encoded[i]=le.fit_transform(dataset_encoded[i])\n",
        "\n",
        "dataset_encoded"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>acade-year</th>\n",
              "      <th>label</th>\n",
              "      <th>scale</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>where</th>\n",
              "      <th>status</th>\n",
              "      <th>finan</th>\n",
              "      <th>copeup</th>\n",
              "      <th>fam</th>\n",
              "      <th>pressure</th>\n",
              "      <th>result</th>\n",
              "      <th>livingplace</th>\n",
              "      <th>support</th>\n",
              "      <th>smedia</th>\n",
              "      <th>infer</th>\n",
              "      <th>meal</th>\n",
              "      <th>sick</th>\n",
              "      <th>hobby</th>\n",
              "      <th>sleep</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1003</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1004</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1005</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1006</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1007</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1007 rows Ã— 20 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      acade-year  label  scale  gender  age  ...  infer  meal  sick  hobby  sleep\n",
              "1              3      2     27       0    3  ...      3     2     0      0      4\n",
              "2              3      1     31       0    3  ...      1     2     1      0      2\n",
              "3              1      0      6       0    3  ...      3     2     1      1      2\n",
              "4              2      0      6       0    3  ...      3     2     1      1      2\n",
              "5              0      2     16       0    3  ...      3     2     1      1      2\n",
              "...          ...    ...    ...     ...  ...  ...    ...   ...   ...    ...    ...\n",
              "1003           2      2     26       0    2  ...      1     2     0      1      3\n",
              "1004           2      2     26       0    2  ...      1     2     0      1      3\n",
              "1005           2      2     26       0    2  ...      1     2     0      1      3\n",
              "1006           2      2     26       0    2  ...      1     2     0      1      3\n",
              "1007           1      1     31       0    1  ...      1     2     0      1      3\n",
              "\n",
              "[1007 rows x 20 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpDhGJ_sAhjg"
      },
      "source": [
        "feature_cols = ['acade-year', 'scale', 'gender', 'age', 'where', 'status', 'finan', 'copeup', 'fam', 'pressure', 'result', 'livingplace', 'support', 'smedia', 'infer', 'meal', 'sick', 'hobby', 'sleep']\n",
        "X = dataset_encoded[feature_cols] # Features\n",
        "y = dataset_encoded.label # Target variable"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l96-kOGzAmKk"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_011oYwo8is"
      },
      "source": [
        "import numbers\n",
        "import warnings\n",
        "from abc import ABCMeta\n",
        "from abc import abstractmethod\n",
        "from math import ceil\n",
        "\n",
        "import numpy as np\n",
        "from scipy.sparse import issparse\n",
        "\n",
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.base import ClassifierMixin\n",
        "from sklearn.base import clone\n",
        "from sklearn.base import is_classifier\n",
        "from sklearn.base import MultiOutputMixin\n",
        "from sklearn.utils import Bunch\n",
        "from sklearn.utils import check_array\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.utils.validation import _check_sample_weight\n",
        "from sklearn.utils import compute_sample_weight\n",
        "from sklearn.utils.multiclass import check_classification_targets\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "\n",
        "from sklearn.tree._criterion import Criterion\n",
        "from sklearn.tree._splitter import Splitter\n",
        "from sklearn.tree._tree import DepthFirstTreeBuilder\n",
        "from sklearn.tree._tree import BestFirstTreeBuilder\n",
        "from sklearn.tree._tree import Tree\n",
        "from sklearn.tree._tree import _build_pruned_tree_ccp\n",
        "from sklearn.tree._tree import ccp_pruning_path\n",
        "from sklearn.tree import _tree, _splitter, _criterion\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "DTYPE = _tree.DTYPE\n",
        "DOUBLE = _tree.DOUBLE\n",
        "\n",
        "CRITERIA_CLF = {\"gini\": _criterion.Gini, \"entropy\": _criterion.Entropy}\n",
        "CRITERIA_REG = {\"mse\": _criterion.MSE, \"friedman_mse\": _criterion.FriedmanMSE,\n",
        "                \"mae\": _criterion.MAE}\n",
        "\n",
        "DENSE_SPLITTERS = {\"best\": _splitter.BestSplitter,\n",
        "                   \"random\": _splitter.RandomSplitter}\n",
        "\n",
        "SPARSE_SPLITTERS = {\"best\": _splitter.BestSparseSplitter,\n",
        "                    \"random\": _splitter.RandomSparseSplitter}"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRjoI-38oPyv"
      },
      "source": [
        "class BaseDecisionTree(MultiOutputMixin, BaseEstimator, metaclass=ABCMeta):\n",
        "\n",
        "    @abstractmethod\n",
        "    def __init__(self,\n",
        "                 criterion,\n",
        "                 splitter,\n",
        "                 max_depth,\n",
        "                 min_samples_split,\n",
        "                 min_samples_leaf,\n",
        "                 min_weight_fraction_leaf,\n",
        "                 max_features,\n",
        "                 max_leaf_nodes,\n",
        "                 random_state,\n",
        "                 min_impurity_decrease,\n",
        "                 min_impurity_split,\n",
        "                 class_weight=None,\n",
        "                 presort='deprecated',\n",
        "                 ccp_alpha=0.0):\n",
        "        self.criterion = criterion\n",
        "        self.splitter = splitter\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.min_samples_leaf = min_samples_leaf\n",
        "        self.min_weight_fraction_leaf = min_weight_fraction_leaf\n",
        "        self.max_features = max_features\n",
        "        self.random_state = random_state\n",
        "        self.max_leaf_nodes = max_leaf_nodes\n",
        "        self.min_impurity_decrease = min_impurity_decrease\n",
        "        self.min_impurity_split = min_impurity_split\n",
        "        self.class_weight = class_weight\n",
        "        self.presort = presort\n",
        "        self.ccp_alpha = ccp_alpha\n",
        "\n",
        "    def get_depth(self):\n",
        "        check_is_fitted(self)\n",
        "        return self.tree_.max_depth\n",
        "\n",
        "    def get_n_leaves(self):\n",
        "        \n",
        "        check_is_fitted(self)\n",
        "        return self.tree_.n_leaves\n",
        "\n",
        "    def fit(self, X, y, sample_weight=None, check_input=True,\n",
        "            X_idx_sorted=None):\n",
        "\n",
        "        random_state = check_random_state(self.random_state)\n",
        "\n",
        "\n",
        "        if check_input:\n",
        "            X = check_array(X, dtype=DTYPE, accept_sparse=\"csc\")\n",
        "            y = check_array(y, ensure_2d=False, dtype=None)\n",
        "            if issparse(X):\n",
        "                X.sort_indices()\n",
        "\n",
        "\n",
        "        # Determine output settings\n",
        "        n_samples, self.n_features_ = X.shape\n",
        "        is_classification = is_classifier(self)\n",
        "\n",
        "        y = np.atleast_1d(y)\n",
        "        expanded_class_weight = None\n",
        "\n",
        "        if y.ndim == 1:\n",
        "            # reshape is necessary to preserve the data contiguity against vs\n",
        "            # [:, np.newaxis] that does not.\n",
        "            y = np.reshape(y, (-1, 1))\n",
        "\n",
        "        self.n_outputs_ = y.shape[1]\n",
        "\n",
        "        if is_classification:\n",
        "            check_classification_targets(y)\n",
        "            y = np.copy(y)\n",
        "\n",
        "            self.classes_ = []\n",
        "            self.n_classes_ = []\n",
        "\n",
        "            if self.class_weight is not None:\n",
        "                y_original = np.copy(y)\n",
        "\n",
        "            y_encoded = np.zeros(y.shape, dtype=np.int)\n",
        "            for k in range(self.n_outputs_):\n",
        "                classes_k, y_encoded[:, k] = np.unique(y[:, k],\n",
        "                                                       return_inverse=True)\n",
        "                self.classes_.append(classes_k)\n",
        "                self.n_classes_.append(classes_k.shape[0])\n",
        "            y = y_encoded\n",
        "\n",
        "            if self.class_weight is not None:\n",
        "                expanded_class_weight = compute_sample_weight(\n",
        "                    self.class_weight, y_original)\n",
        "\n",
        "            self.n_classes_ = np.array(self.n_classes_, dtype=np.intp)\n",
        "\n",
        "        if getattr(y, \"dtype\", None) != DOUBLE or not y.flags.contiguous:\n",
        "            y = np.ascontiguousarray(y, dtype=DOUBLE)\n",
        "\n",
        "        # Check parameters\n",
        "        max_depth = (np.iinfo(np.int32).max if self.max_depth is None\n",
        "                     else self.max_depth)\n",
        "        max_leaf_nodes = (-1 if self.max_leaf_nodes is None\n",
        "                          else self.max_leaf_nodes)\n",
        "\n",
        "        if isinstance(self.min_samples_leaf, numbers.Integral):\n",
        "            if not 1 <= self.min_samples_leaf:\n",
        "                raise ValueError(\"min_samples_leaf must be at least 1 \"\n",
        "                                 \"or in (0, 0.5], got %s\"\n",
        "                                 % self.min_samples_leaf)\n",
        "            min_samples_leaf = self.min_samples_leaf\n",
        "        else:  # float\n",
        "            if not 0. < self.min_samples_leaf <= 0.5:\n",
        "                raise ValueError(\"min_samples_leaf must be at least 1 \"\n",
        "                                 \"or in (0, 0.5], got %s\"\n",
        "                                 % self.min_samples_leaf)\n",
        "            min_samples_leaf = int(ceil(self.min_samples_leaf * n_samples))\n",
        "\n",
        "        if isinstance(self.min_samples_split, numbers.Integral):\n",
        "            if not 2 <= self.min_samples_split:\n",
        "                raise ValueError(\"min_samples_split must be an integer \"\n",
        "                                 \"greater than 1 or a float in (0.0, 1.0]; \"\n",
        "                                 \"got the integer %s\"\n",
        "                                 % self.min_samples_split)\n",
        "            min_samples_split = self.min_samples_split\n",
        "        else:  # float\n",
        "            if not 0. < self.min_samples_split <= 1.:\n",
        "                raise ValueError(\"min_samples_split must be an integer \"\n",
        "                                 \"greater than 1 or a float in (0.0, 1.0]; \"\n",
        "                                 \"got the float %s\"\n",
        "                                 % self.min_samples_split)\n",
        "            min_samples_split = int(ceil(self.min_samples_split * n_samples))\n",
        "            min_samples_split = max(2, min_samples_split)\n",
        "\n",
        "        min_samples_split = max(min_samples_split, 2 * min_samples_leaf)\n",
        "\n",
        "        if isinstance(self.max_features, str):\n",
        "            if self.max_features == \"auto\":\n",
        "                if is_classification:\n",
        "                    max_features = max(1, int(np.sqrt(self.n_features_)))\n",
        "                else:\n",
        "                    max_features = self.n_features_\n",
        "            elif self.max_features == \"sqrt\":\n",
        "                max_features = max(1, int(np.sqrt(self.n_features_)))\n",
        "            elif self.max_features == \"log2\":\n",
        "                max_features = max(1, int(np.log2(self.n_features_)))\n",
        "            else:\n",
        "                raise ValueError(\"Invalid value for max_features. \"\n",
        "                                 \"Allowed string values are 'auto', \"\n",
        "                                 \"'sqrt' or 'log2'.\")\n",
        "        elif self.max_features is None:\n",
        "            max_features = self.n_features_\n",
        "        elif isinstance(self.max_features, numbers.Integral):\n",
        "            max_features = self.max_features\n",
        "        else:  # float\n",
        "            if self.max_features > 0.0:\n",
        "                max_features = max(1,\n",
        "                                   int(self.max_features * self.n_features_))\n",
        "            else:\n",
        "                max_features = 0\n",
        "\n",
        "        self.max_features_ = max_features\n",
        "\n",
        "        if len(y) != n_samples:\n",
        "            raise ValueError(\"Number of labels=%d does not match \"\n",
        "                             \"number of samples=%d\" % (len(y), n_samples))\n",
        "        if not 0 <= self.min_weight_fraction_leaf <= 0.5:\n",
        "            raise ValueError(\"min_weight_fraction_leaf must in [0, 0.5]\")\n",
        "        if max_depth <= 0:\n",
        "            raise ValueError(\"max_depth must be greater than zero. \")\n",
        "        if not (0 < max_features <= self.n_features_):\n",
        "            raise ValueError(\"max_features must be in (0, n_features]\")\n",
        "        if not isinstance(max_leaf_nodes, numbers.Integral):\n",
        "            raise ValueError(\"max_leaf_nodes must be integral number but was \"\n",
        "                             \"%r\" % max_leaf_nodes)\n",
        "        if -1 < max_leaf_nodes < 2:\n",
        "            raise ValueError((\"max_leaf_nodes {0} must be either None \"\n",
        "                              \"or larger than 1\").format(max_leaf_nodes))\n",
        "\n",
        "        if sample_weight is not None:\n",
        "            sample_weight = _check_sample_weight(sample_weight, X, DOUBLE)\n",
        "\n",
        "        if expanded_class_weight is not None:\n",
        "            if sample_weight is not None:\n",
        "                sample_weight = sample_weight * expanded_class_weight\n",
        "            else:\n",
        "                sample_weight = expanded_class_weight\n",
        "\n",
        "        # Set min_weight_leaf from min_weight_fraction_leaf\n",
        "        if sample_weight is None:\n",
        "            min_weight_leaf = (self.min_weight_fraction_leaf *\n",
        "                               n_samples)\n",
        "        else:\n",
        "            min_weight_leaf = (self.min_weight_fraction_leaf *\n",
        "                               np.sum(sample_weight))\n",
        "\n",
        "        \n",
        "        if self.min_impurity_split is not None:\n",
        "            min_impurity_split = self.min_impurity_split\n",
        "        else:\n",
        "            min_impurity_split = 1e-7\n",
        "\n",
        "        if min_impurity_split < 0.:\n",
        "            raise ValueError(\"min_impurity_split must be greater than \"\n",
        "                             \"or equal to 0\")\n",
        "\n",
        "        if self.min_impurity_decrease < 0.:\n",
        "            raise ValueError(\"min_impurity_decrease must be greater than \"\n",
        "                             \"or equal to 0\")\n",
        "\n",
        "       \n",
        "\n",
        "        # Build tree\n",
        "        criterion = self.criterion\n",
        "        if not isinstance(criterion, Criterion):\n",
        "            if is_classification:\n",
        "                criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
        "                                                         self.n_classes_)\n",
        "            else:\n",
        "                criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
        "                                                         n_samples)\n",
        "\n",
        "        SPLITTERS = SPARSE_SPLITTERS if issparse(X) else DENSE_SPLITTERS\n",
        "\n",
        "        splitter = self.splitter\n",
        "        if not isinstance(self.splitter, Splitter):\n",
        "            splitter = SPLITTERS[self.splitter](criterion,\n",
        "                                                self.max_features_,\n",
        "                                                min_samples_leaf,\n",
        "                                                min_weight_leaf,\n",
        "                                                random_state)\n",
        "\n",
        "        if is_classifier(self):\n",
        "            self.tree_ = Tree(self.n_features_,\n",
        "                              self.n_classes_, self.n_outputs_)\n",
        "        else:\n",
        "            self.tree_ = Tree(self.n_features_,\n",
        "                              # TODO: tree should't need this in this case\n",
        "                              np.array([1] * self.n_outputs_, dtype=np.intp),\n",
        "                              self.n_outputs_)\n",
        "\n",
        "        # Use BestFirst if max_leaf_nodes given; use DepthFirst otherwise\n",
        "        if max_leaf_nodes < 0:\n",
        "            builder = DepthFirstTreeBuilder(splitter, min_samples_split,\n",
        "                                            min_samples_leaf,\n",
        "                                            min_weight_leaf,\n",
        "                                            max_depth,\n",
        "                                            self.min_impurity_decrease,\n",
        "                                            min_impurity_split)\n",
        "        else:\n",
        "            builder = BestFirstTreeBuilder(splitter, min_samples_split,\n",
        "                                           min_samples_leaf,\n",
        "                                           min_weight_leaf,\n",
        "                                           max_depth,\n",
        "                                           max_leaf_nodes,\n",
        "                                           self.min_impurity_decrease,\n",
        "                                           min_impurity_split)\n",
        "\n",
        "        builder.build(self.tree_, X, y, sample_weight, X_idx_sorted)\n",
        "\n",
        "        if self.n_outputs_ == 1 and is_classifier(self):\n",
        "            self.n_classes_ = self.n_classes_[0]\n",
        "            self.classes_ = self.classes_[0]\n",
        "\n",
        "        self._prune_tree()\n",
        "\n",
        "        return self\n",
        "\n",
        "    def _validate_X_predict(self, X, check_input):\n",
        "        \"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\n",
        "        if check_input:\n",
        "            X = check_array(X, dtype=DTYPE, accept_sparse=\"csr\")\n",
        "            if issparse(X) and (X.indices.dtype != np.intc or\n",
        "                                X.indptr.dtype != np.intc):\n",
        "                raise ValueError(\"No support for np.int64 index based \"\n",
        "                                 \"sparse matrices\")\n",
        "\n",
        "        n_features = X.shape[1]\n",
        "        if self.n_features_ != n_features:\n",
        "            raise ValueError(\"Number of features of the model must \"\n",
        "                             \"match the input. Model n_features is %s and \"\n",
        "                             \"input n_features is %s \"\n",
        "                             % (self.n_features_, n_features))\n",
        "\n",
        "        return X\n",
        "\n",
        "    def predict(self, X, check_input=True):\n",
        "        check_is_fitted(self)\n",
        "        X = self._validate_X_predict(X, check_input)\n",
        "        proba = self.tree_.predict(X)\n",
        "        n_samples = X.shape[0]\n",
        "\n",
        "        # Classification\n",
        "        if is_classifier(self):\n",
        "            if self.n_outputs_ == 1:\n",
        "                return self.classes_.take(np.argmax(proba, axis=1), axis=0)\n",
        "\n",
        "            else:\n",
        "                class_type = self.classes_[0].dtype\n",
        "                predictions = np.zeros((n_samples, self.n_outputs_),\n",
        "                                       dtype=class_type)\n",
        "                for k in range(self.n_outputs_):\n",
        "                    predictions[:, k] = self.classes_[k].take(\n",
        "                        np.argmax(proba[:, k], axis=1),\n",
        "                        axis=0)\n",
        "\n",
        "                return predictions\n",
        "\n",
        "    def apply(self, X, check_input=True):\n",
        "\n",
        "        check_is_fitted(self)\n",
        "        X = self._validate_X_predict(X, check_input)\n",
        "        return self.tree_.apply(X)\n",
        "\n",
        "    def decision_path(self, X, check_input=True):\n",
        "\n",
        "        X = self._validate_X_predict(X, check_input)\n",
        "        return self.tree_.decision_path(X)\n",
        "\n",
        "    def _prune_tree(self):\n",
        "        \"\"\"Prune tree using Minimal Cost-Complexity Pruning.\"\"\"\n",
        "        check_is_fitted(self)\n",
        "\n",
        "        if self.ccp_alpha < 0.0:\n",
        "            raise ValueError(\"ccp_alpha must be greater than or equal to 0\")\n",
        "\n",
        "        if self.ccp_alpha == 0.0:\n",
        "            return\n",
        "\n",
        "        # build pruned tree\n",
        "        if is_classifier(self):\n",
        "            n_classes = np.atleast_1d(self.n_classes_)\n",
        "            pruned_tree = Tree(self.n_features_, n_classes, self.n_outputs_)\n",
        "        else:\n",
        "            pruned_tree = Tree(self.n_features_,\n",
        "                               # TODO: the tree shouldn't need this param\n",
        "                               np.array([1] * self.n_outputs_, dtype=np.intp),\n",
        "                               self.n_outputs_)\n",
        "        _build_pruned_tree_ccp(pruned_tree, self.tree_, self.ccp_alpha)\n",
        "\n",
        "        self.tree_ = pruned_tree\n",
        "\n",
        "    def cost_complexity_pruning_path(self, X, y, sample_weight=None):\n",
        "        \n",
        "        est = clone(self).set_params(ccp_alpha=0.0)\n",
        "        est.fit(X, y, sample_weight=sample_weight)\n",
        "        return Bunch(**ccp_pruning_path(est.tree_))\n",
        "\n",
        "    @property\n",
        "    def feature_importances_(self):\n",
        "        \n",
        "        check_is_fitted(self)\n",
        "\n",
        "        return self.tree_.compute_feature_importances()\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAWnLViLtwQA"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class DecisionTree(ClassifierMixin, BaseDecisionTree):\n",
        "    \n",
        "    def __init__(self,\n",
        "                 criterion=\"gini\",\n",
        "                 splitter=\"best\",\n",
        "                 max_depth=None,\n",
        "                 min_samples_split=2,\n",
        "                 min_samples_leaf=1,\n",
        "                 min_weight_fraction_leaf=0.,\n",
        "                 max_features=None,\n",
        "                 random_state=None,\n",
        "                 max_leaf_nodes=None,\n",
        "                 min_impurity_decrease=0.,\n",
        "                 min_impurity_split=None,\n",
        "                 class_weight=None,\n",
        "                 presort='deprecated',\n",
        "                 ccp_alpha=0.0):\n",
        "        super().__init__(\n",
        "            criterion=criterion,\n",
        "            splitter=splitter,\n",
        "            max_depth=max_depth,\n",
        "            min_samples_split=min_samples_split,\n",
        "            min_samples_leaf=min_samples_leaf,\n",
        "            min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
        "            max_features=max_features,\n",
        "            max_leaf_nodes=max_leaf_nodes,\n",
        "            class_weight=class_weight,\n",
        "            random_state=random_state,\n",
        "            min_impurity_decrease=min_impurity_decrease,\n",
        "            min_impurity_split=min_impurity_split,\n",
        "            presort=presort,\n",
        "            ccp_alpha=ccp_alpha)\n",
        "\n",
        "    def fit(self, X, y, sample_weight=None, check_input=True,\n",
        "            X_idx_sorted=None):\n",
        "        \n",
        "\n",
        "        super().fit(\n",
        "            X, y,\n",
        "            sample_weight=sample_weight,\n",
        "            check_input=check_input,\n",
        "            X_idx_sorted=X_idx_sorted)\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, X, check_input=True):\n",
        "        \n",
        "        check_is_fitted(self)\n",
        "        X = self._validate_X_predict(X, check_input)\n",
        "        proba = self.tree_.predict(X)\n",
        "\n",
        "        if self.n_outputs_ == 1:\n",
        "            proba = proba[:, :self.n_classes_]\n",
        "            normalizer = proba.sum(axis=1)[:, np.newaxis]\n",
        "            normalizer[normalizer == 0.0] = 1.0\n",
        "            proba /= normalizer\n",
        "\n",
        "            return proba\n",
        "\n",
        "        else:\n",
        "            all_proba = []\n",
        "\n",
        "            for k in range(self.n_outputs_):\n",
        "                proba_k = proba[:, k, :self.n_classes_[k]]\n",
        "                normalizer = proba_k.sum(axis=1)[:, np.newaxis]\n",
        "                normalizer[normalizer == 0.0] = 1.0\n",
        "                proba_k /= normalizer\n",
        "                all_proba.append(proba_k)\n",
        "\n",
        "            return all_proba\n",
        "\n",
        "  \n",
        "    "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYy4vHjiAtu9"
      },
      "source": [
        "clf = DecisionTree()\n",
        "\n",
        "# Train Decision Tree Classifer\n",
        "clf = clf.fit(X_train,y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = clf.predict(X_test)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAh5epPPPNU3",
        "outputId": "dc3b775f-3f51-4298-86a4-8fa98bc8e2ac"
      },
      "source": [
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9702970297029703\n"
          ]
        }
      ]
    }
  ]
}